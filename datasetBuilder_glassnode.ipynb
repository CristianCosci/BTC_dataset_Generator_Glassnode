{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datasetBuilder_glassnode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0NmDyJVgKei/9TPgSnqRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristianCosci/BTC_dataset_Generator_glassnode/blob/main/datasetBuilder_glassnode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3fk7XyvKGENu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51b6430-c9fd-4867-adcb-b97268c81736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import math\n",
        "\n",
        "connected = False\n",
        "\n",
        "if(not connected):\n",
        "  drive.mount('/content/drive', force_remount= True)\n",
        "  path = '/content/drive/MyDrive/progettoBTC/'\n",
        "  connected = True\n",
        "  f = open(\"{}secret.txt\".format(path))\n",
        "  API_KEY = f.read().replace(\"\\n\", \"\")\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getEMA(df, time):\n",
        "  multiplier = 2 / (time + 1)\n",
        "  name = \"SMA_\" + str(time)\n",
        "  name1 = \"EMA_\" + str(time)\n",
        "  df[name] = df.close.rolling(window=time).mean() #calcolo sma_time in modo da utilizzarla per il primo ema\n",
        "  df[name1] = df[name]\n",
        "  for i in range(1, len(df)):\n",
        "    if(not math.isnan(df[name1][i-1])):\n",
        "      df[name1][i] = (df['close'][i] * multiplier) + (df[name1][i-1] * (1 - multiplier))\n",
        "\n",
        "  return df[name1]\n",
        "\n",
        "def getMACD(df):\n",
        "  name = \"MACD\" \n",
        "  df[name] = df[\"EMA_12\"] - df[\"EMA_26\"]\n",
        "\n",
        "  return df[name]\n",
        "\n",
        "def getKD(df, time_k, time_d):\n",
        "  name_k = \"K_\" + str(time_k)\n",
        "  name_d = \"D_\" + str(time_d)\n",
        "  df[name_k] = df[\"close\"]\n",
        "  df[name_d] = df[\"close\"]\n",
        "  for i in range(time_k, len(df)):\n",
        "    df[name_k][i] = ( df[name_k][i] - df[\"low\"].iloc[i-time_k:i].min() ) / ( df[\"high\"].iloc[i-time_k:i].max() - df[\"low\"].iloc[i-time_k:i].min())\n",
        "    df[name_k][i] *= 100\n",
        "  for i in range(time_k + time_d, len(df)):\n",
        "    sum = 0\n",
        "    for j in range(time_d):\n",
        "      sum += df[name_k][i-j]\n",
        "    df[name_d] = sum / time_d\n",
        "\n",
        "  return df[name_k] * df[name_d]\n",
        "\n",
        "def getRSI(df):\n",
        "  delta = df['close'].diff()\n",
        "  up = delta.clip(lower=0)\n",
        "  down = -1*delta.clip(upper=0)\n",
        "  sma_up = up.rolling(window=14).mean()\n",
        "  sma_down = down.rolling(window=14).mean()\n",
        "  rs = sma_up/sma_down\n",
        "  df['RSI'] = 100 - (100/(1 + rs))\n",
        "\n",
        "  return df['RSI']\n",
        "\n",
        "def getWR(df, time):\n",
        "  name = \"WR_\" + str(time)\n",
        "  df[name] = df[\"close\"]\n",
        "  for i in range(time, len(df)):\n",
        "    df[name][i] = ( df[\"high\"].iloc[i-time:i].max() - df[name][i] ) / ( df[\"high\"].iloc[i-time:i].max() - df[\"low\"].iloc[i-time:i].min())\n",
        "    df[name][i] *= 100\n",
        "  \n",
        "  return df[name]\n",
        "\n",
        "\n",
        "def get_financial_data(df):\n",
        "  print()\n",
        "  print('CALCULATING FINANCIAL INDICATOR')\n",
        "  #CALCULATE SIMPLE MOVING AVERAGE \n",
        "  df['SMA_50'] = df.close.rolling(window=50).mean()\n",
        "  df['SMA_200'] = df.close.rolling(window=200).mean()\n",
        "\n",
        "  #CALCULATE EMA\n",
        "  df['EMA_12'] = getEMA(df.copy(), 12)\n",
        "  df['EMA_26'] = getEMA(df.copy(), 26)\n",
        "\n",
        "  #CALCULATE MACD\n",
        "  df['MACD'] = getMACD(df.copy())\n",
        "\n",
        "  #CALCULATE KD\n",
        "  df['KD'] = getKD(df.copy(), time_k=14, time_d=3)\n",
        "\n",
        "  #CALCULATE RSI\n",
        "  df['RSI'] = getRSI(df.copy())\n",
        "\n",
        "  #CALCULATE WR\n",
        "  df['WR_14'] = getWR(df.copy(), time=14)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def download_dataset(df, interval, since, dataset_path, coin):\n",
        "  query_total = [] # To store an array of dict, each for every query\n",
        "  with open(path+dataset_path,'r') as file:\n",
        "    # reading each line\n",
        "    for line in file:\n",
        "        count = 0\n",
        "        # print(line)\n",
        "        link = line.split()[0] # The first element of the line is the link for the query\n",
        "        query = {'link': link} # Put in a dict\n",
        "        labels = [] # To store the word of the line\n",
        "        for word in line.split()[1:]: # Split the word of the line\n",
        "            labels.append(word)\n",
        "            count += 1\n",
        "        for i in range(0, count, 2): # Step of 2 on reading, beacause need couple (name in new df, name returned by query)\n",
        "          query[labels[i]] = labels[i+1]\n",
        "          # print(query)\n",
        "        query_total.append(query)\n",
        "        query = {} # Reset dict\n",
        "\n",
        "  num_richieste = 0\n",
        "  for i in query_total:\n",
        "    link = i.pop('link')\n",
        "    # print(link)\n",
        "    res = requests.get(link,\n",
        "    params={'a': coin, 's': since,'i': interval, 'api_key': API_KEY})\n",
        "    foo_df = pd.json_normalize(json.loads(res.text))\n",
        "    foo_df[\"datetime\"] = pd.to_datetime(foo_df[\"t\"], unit=\"s\") #timestamp conversion to datetime\n",
        "    foo_df = foo_df.drop(\"t\", axis=1).set_index(\"datetime\").sort_index()\n",
        "    for j in i.keys(): # To add a new column in the real dataset -> using couple (name in new df, name returned by query)\n",
        "      num_richieste += 1\n",
        "      print(j)\n",
        "      df[j] = foo_df[i[j]]\n",
        "\n",
        "  print('Numero richieste per {} {}'.format(coin, num_richieste))\n",
        "  return df\n",
        "\n",
        "\n",
        "def get_data(interval, since, dataset_path, eth_data=False, coin='BTC', financial_data = False):\n",
        "  assert interval == '1h' or interval == '24h'\n",
        "  df = pd.DataFrame()\n",
        "  df = download_dataset(df, interval, since, dataset_path, coin)\n",
        "  if eth_data: # If requested download also eth data\n",
        "    print()\n",
        "    print('ETH DATA')\n",
        "    coin = 'ETH'\n",
        "    if interval == '1h':\n",
        "      dataset_path = 'hourly_data_eth.txt'\n",
        "    elif interval == '24h':\n",
        "      dataset_path = 'daily_data_eth.txt'\n",
        "    df = download_dataset(df, interval, since, dataset_path, coin)\n",
        "    if financial_data:\n",
        "      df = get_financial_data(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "LBrxolCyjlyS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hourly = get_data(interval = '1h', since = '1333238400', dataset_path = 'hourly_data.txt', eth_data = True, financial_data = True) # data from Sunday 1 April 2012 00:00:00\n",
        "df_daily = get_data(interval = '24h', since = '1333238400', dataset_path = 'daily_data.txt', eth_data = True, financial_data = True)"
      ],
      "metadata": {
        "id": "pXTHwnMsK1G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hourly.to_csv(path+\"BTC_hourly_dataset.csv\")\n",
        "df_daily.to_csv(path+\"BTC_daily_dataset.csv\")"
      ],
      "metadata": {
        "id": "dY_r33dQLYrV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR DEBUG\n",
        "res = requests.get('https://api.glassnode.com/v1/metrics/supply/active_24h' ,\n",
        "    params={'a': 'ETH','s': '1356998400','i': '24h', 'api_key': API_KEY})\n",
        "foo_df = pd.json_normalize(json.loads(res.text))\n",
        "print(foo_df)\n",
        "foo_df[\"datetime\"] = pd.to_datetime(foo_df[\"t\"], unit=\"s\") #timestamp conversion to datetime\n",
        "foo_df = foo_df.drop(\"t\", axis=1).set_index(\"datetime\").sort_index()"
      ],
      "metadata": {
        "id": "05OQtfphPkNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foo_df"
      ],
      "metadata": {
        "id": "ny8KUt0oG7hL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}